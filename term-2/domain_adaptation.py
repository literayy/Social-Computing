import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.autograd import Function
from transformers import DebertaV2Tokenizer, DebertaV2Model, get_linear_schedule_with_warmup
import pandas as pd
import numpy as np
import os
import gc
import time
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import random

# ==================== æ¢¯åº¦åè½¬å±‚ (ä¼˜åŒ–ï¼šåŠ¨æ€alpha + ç¨³å®šæ¢¯åº¦) ====================
class GradientReversalFunction(Function):
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha
        return x.view_as(x)
    
    @staticmethod
    def backward(ctx, grad_output):
        output = grad_output.neg() * ctx.alpha
        return output, None

class GradientReversalLayer(nn.Module):
    def __init__(self, alpha=1.0):
        super().__init__()
        self.alpha = alpha
    
    def forward(self, x):
        return GradientReversalFunction.apply(x, self.alpha)
    
    def set_alpha(self, alpha):
        """æ–°å¢ï¼šåŠ¨æ€è°ƒæ•´alphaå€¼ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰"""
        self.alpha = alpha

# ==================== æ•°æ®é›†ç±» (ä¼˜åŒ–ï¼šæ€§åˆ«åˆ†ç±»æ ·æœ¬å¹³è¡¡) ===================
class DualDomainDataset(Dataset):
    def __init__(self, df, tokenizer, max_length, config):
        self.df = df.reset_index(drop=True)
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.config = config
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        
        encoding = self.tokenizer(
            row['text'],
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        domain_label = 0 if row['domain'] == 'cresci' else 1
        task_label = int(row['label'])
        
        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'domain_label': torch.tensor(domain_label, dtype=torch.long),
            'task_label': torch.tensor(task_label, dtype=torch.long),
            'domain': row['domain'],
            'idx': torch.tensor(idx, dtype=torch.long)
        }

# ==================== åŸŸé€‚åº”æ¨¡å‹ (æ ¸å¿ƒä¼˜åŒ–ï¼šå¢å¼ºåˆ†ç±»å™¨+ç¨³å®šè®­ç»ƒ) ====================
class DomainAdaptiveDeBERTa(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        self.deberta = DebertaV2Model.from_pretrained(config.DEBERTA_PATH)
        self.hidden_size = self.deberta.config.hidden_size
        print(f"âœ“ DeBERTa hidden_size: {self.hidden_size}")
        
        # åˆå§‹åŒ–GRLï¼ˆé»˜è®¤alphaé™ä½ï¼Œé¿å…æ¢¯åº¦åè½¬è¿‡å¼ºï¼‰
        self.grl = GradientReversalLayer(alpha=config.GRL_ALPHA if hasattr(config, 'GRL_ALPHA') else 0.3)
        
        # ä¼˜åŒ–1ï¼šå¢å¼ºåŸŸåˆ†ç±»å™¨ï¼ˆè§£å†³åŸŸåˆ¤åˆ«å‡†ç¡®ç‡è¿‡ä½ï¼‰
        self.domain_classifier = nn.Sequential(
            nn.Linear(self.hidden_size, 512),
            nn.LayerNorm(512),  # æ–°å¢å±‚å½’ä¸€åŒ–ï¼Œç¨³å®šè®­ç»ƒ
            nn.ReLU(),
            nn.Dropout(0.3),    # æé«˜dropoutï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, config.NUM_DOMAINS)
        )
        
        # Botåˆ†ç±»å™¨ä¿æŒï¼ˆåŸæœ‰æ•ˆæœå¥½ï¼‰
        self.bot_classifier = nn.Sequential(
            nn.Linear(self.hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, config.NUM_BOT_CLASSES)
        )
        
        # ä¼˜åŒ–2ï¼šå¢å¼ºæ€§åˆ«åˆ†ç±»å™¨ï¼ˆè§£å†³å‡†ç¡®ç‡ä½ï¼‰
        self.gender_classifier = nn.Sequential(
            nn.Linear(self.hidden_size, 512),
            nn.LayerNorm(512),  # æ–°å¢å±‚å½’ä¸€åŒ–
            nn.ReLU(),
            nn.Dropout(0.3),    # æé«˜dropout
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, config.NUM_GENDER_CLASSES)
        )
    
    def forward(self, input_ids, attention_mask, domain):
        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)
        features = outputs.last_hidden_state[:, 0, :]
        
        reversed_features = self.grl(features)
        domain_logits = self.domain_classifier(reversed_features)
        
        bot_logits = self.bot_classifier(features)
        gender_logits = self.gender_classifier(features)
        
        return {
            'features': features,
            'domain_logits': domain_logits,
            'bot_logits': bot_logits,
            'gender_logits': gender_logits
        }

# ==================== æ ‡ç­¾å¹³æ»‘æŸå¤± (æ–°å¢ï¼šå‡å°‘è¿‡æ‹Ÿåˆ) ====================
class LabelSmoothingLoss(nn.Module):
    def __init__(self, classes, smoothing=0.1, dim=-1):
        super().__init__()
        self.confidence = 1.0 - smoothing
        self.smoothing = smoothing
        self.cls = classes
        self.dim = dim

    def forward(self, pred, target):
        pred = pred.log_softmax(dim=self.dim)
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.cls - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))

# ==================== è®­ç»ƒå™¨ (æ ¸å¿ƒä¼˜åŒ–ï¼šæ— åŸæ¨¡å‹æ—¶ä»0è®­ç»ƒ) ====================
class DomainAdaptationTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        if torch.cuda.is_available():
            total_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"GPUæ€»å†…å­˜: {total_mem:.2f} GB")
        
        self._set_seed()
        self.tokenizer = self._load_tokenizer()
        self.model = self._build_model()
        
        # åŠ è½½å·²æœ‰best_model.ptï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šæ— æ¨¡å‹æ—¶è·³è¿‡ï¼‰
        self.original_model_path = r"F:\social-compute\output\models\best_model.pt"
        self._load_pretrained_model()  # ä¿®æ”¹åçš„åŠ è½½é€»è¾‘
        
        # è®­ç»ƒå†å²å’Œæœ€ä¼˜æŒ‡æ ‡
        self.history = {
            'train_loss': [], 'train_acc': [],
            'val_acc': [], 'domain_acc': [],  # æ–°å¢åŸŸå‡†ç¡®ç‡è·Ÿè¸ª
            'bot_acc': [], 'gender_acc': []    # æ–°å¢ç»†åˆ†ä»»åŠ¡å‡†ç¡®ç‡
        }
        self.best_val_acc = 0.0  
        self.sampled_indices = set()
        self.full_train_df = None
        self.val_df = None
        self.test_df = None

    def _set_seed(self):
        random.seed(self.config.RANDOM_SEED)
        np.random.seed(self.config.RANDOM_SEED)
        torch.manual_seed(self.config.RANDOM_SEED)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(self.config.RANDOM_SEED)
            torch.cuda.manual_seed_all(self.config.RANDOM_SEED)

    def _load_tokenizer(self):
        try:
            tokenizer = DebertaV2Tokenizer.from_pretrained(self.config.DEBERTA_PATH)
            print("âœ“ TokenizeråŠ è½½æˆåŠŸ")
            return tokenizer
        except Exception as e:
            raise Exception(f"TokenizeråŠ è½½å¤±è´¥: {e}")

    def _build_model(self):
        try:
            model = DomainAdaptiveDeBERTa(self.config).to(self.device)
            print("âœ“ åŸŸé€‚åº”æ¨¡å‹æ„å»ºæˆåŠŸ")
            param_count = sum(p.numel() for p in model.parameters())
            print(f"æ¨¡å‹å‚æ•°é‡: {param_count:,} ({param_count/1e6:.2f}M)")
            return model
        except Exception as e:
            raise Exception(f"æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
    
    def _load_pretrained_model(self):
        """ä¿®æ”¹ï¼šæ— åŸæ¨¡å‹æ—¶è·³è¿‡åŠ è½½ï¼Œä»0å¼€å§‹è®­ç»ƒ"""
        if os.path.exists(self.original_model_path):
            try:
                checkpoint = torch.load(self.original_model_path, map_location=self.device, weights_only=False)
                self.model.load_state_dict(checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint)
                print(f"âœ“ æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {self.original_model_path}")
                print(f"â„¹ï¸  å°†åŸºäºå·²æœ‰æ¨¡å‹è¿›è¡Œå¢é‡è®­ç»ƒ")
            except Exception as e:
                print(f"âš ï¸  æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                print(f"â„¹ï¸  æ”¾å¼ƒåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»0å¼€å§‹è®­ç»ƒ")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°åŸæ¨¡å‹: {self.original_model_path}")
            print(f"â„¹ï¸  ä»0å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹")

    def load_full_data(self):
        print("\n=== åŠ è½½å…¨é‡é¢„å¤„ç†æ•°æ®ï¼ˆæŒ‰7:1.5:1.5åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼‰===")
        # åŠ è½½åŸå§‹æ•°æ®
        cresci_df = pd.read_csv(self.config.PREPROCESSED_CRESCI)
        gender_df = pd.read_csv(self.config.PREPROCESSED_GENDER)

        # æ•°æ®æ¸…æ´—
        cresci_df = cresci_df[cresci_df['text'].str.len() >= self.config.MIN_TEXT_LENGTH].reset_index(drop=True)
        gender_df = gender_df[gender_df['text'].str.len() >= self.config.MIN_TEXT_LENGTH].reset_index(drop=True)

        # å®šä¹‰åˆ’åˆ†å‡½æ•°ï¼ˆä¸¥æ ¼æŒ‰7:1.5:1.5åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼‰
        def split_data(df, train_ratio, val_ratio, test_ratio):
            assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, "æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ä¸º1"
            df = df.sample(frac=1, random_state=self.config.RANDOM_SEED).reset_index(drop=True)
            n = len(df)
            train_end = int(n * train_ratio)
            val_end = train_end + int(n * val_ratio)
            train_df = df[:train_end].reset_index(drop=True)
            val_df = df[train_end:val_end].reset_index(drop=True)
            test_df = df[val_end:].reset_index(drop=True)
            return train_df, val_df, test_df

        # æŒ‰7:1.5:1.5åˆ’åˆ†Cresciå’ŒGenderæ•°æ®é›†
        cresci_train, cresci_val, cresci_test = split_data(
            cresci_df, 
            self.config.TRAIN_RATIO, 
            self.config.VAL_RATIO, 
            self.config.TEST_RATIO
        )
        gender_train, gender_val, gender_test = split_data(
            gender_df, 
            self.config.TRAIN_RATIO, 
            self.config.VAL_RATIO, 
            self.config.TEST_RATIO
        )

        # åˆå¹¶è·¨åŸŸæ•°æ®é›†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•å®Œå…¨ç‹¬ç«‹ï¼‰
        self.full_train_df = pd.concat([cresci_train, gender_train], ignore_index=True)
        val_df_raw = pd.concat([cresci_val, gender_val], ignore_index=True)
        self.test_df = pd.concat([cresci_test, gender_test], ignore_index=True)

        # ä¼˜åŒ–ï¼šæ€§åˆ«åˆ†ç±»åˆ†å±‚æŠ½æ ·ï¼ˆä¿è¯Male/Female/Brandæ ·æœ¬å‡è¡¡ï¼‰
        if len(val_df_raw) >= self.config.MAX_VAL_SAMPLES:
            # å…ˆæŒ‰åŸŸåˆ†å±‚ï¼Œå†æŒ‰æ€§åˆ«æ ‡ç­¾åˆ†å±‚
            val_df_cresci = val_df_raw[val_df_raw['domain'] == 'cresci'].sample(
                n=min(100, len(val_df_raw[val_df_raw['domain'] == 'cresci'])),
                random_state=self.config.RANDOM_SEED
            )
            # æ€§åˆ«åŸŸæŒ‰æ ‡ç­¾åˆ†å±‚æŠ½æ ·
            gender_val_grouped = val_df_raw[val_df_raw['domain'] == 'gender'].groupby('label')
            gender_samples = []
            for label, group in gender_val_grouped:
                sample_size = min(34, len(group))  # 3ç±»å„â‰ˆ34æ¡ï¼Œæ€»è®¡â‰ˆ100æ¡
                gender_samples.append(group.sample(sample_size, random_state=self.config.RANDOM_SEED))
            val_df_gender = pd.concat(gender_samples, ignore_index=True)
            
            self.val_df = pd.concat([val_df_cresci, val_df_gender], ignore_index=True)
            # è¡¥å……åˆ°200æ¡
            if len(self.val_df) < self.config.MAX_VAL_SAMPLES:
                remaining_val = val_df_raw[~val_df_raw.index.isin(self.val_df.index)]
                supplement = remaining_val.sample(n=self.config.MAX_VAL_SAMPLES - len(self.val_df), random_state=self.config.RANDOM_SEED)
                self.val_df = pd.concat([self.val_df, supplement], ignore_index=True).reset_index(drop=True)
        else:
            self.val_df = val_df_raw.reset_index(drop=True)
            print(f"âš ï¸  åŸå§‹éªŒè¯é›†ä»…{len(val_df_raw)}æ¡ï¼Œä¸è¶³200æ¡ï¼Œä½¿ç”¨å…¨éƒ¨ä½œä¸ºéªŒè¯é›†")

        # ç»™è®­ç»ƒé›†åŠ å”¯ä¸€ç´¢å¼•
        self.full_train_df['unique_idx'] = range(len(self.full_train_df))

        # ä¿å­˜éªŒè¯é›†/æµ‹è¯•é›†
        self.val_df.to_csv(os.path.join(self.config.OUTPUT_PATH, "val_set.csv"), index=False)
        self.test_df.to_csv(os.path.join(self.config.OUTPUT_PATH, "test_set.csv"), index=False)

        # æ‰“å°åˆ’åˆ†ç»“æœ
        print(f"Cresci - è®­ç»ƒé›†: {len(cresci_train)} | åŸå§‹éªŒè¯é›†: {len(cresci_val)} | æµ‹è¯•é›†: {len(cresci_test)}")
        print(f"Gender - è®­ç»ƒé›†: {len(gender_train)} | åŸå§‹éªŒè¯é›†: {len(gender_val)} | æµ‹è¯•é›†: {len(gender_test)}")
        print(f"å…¨é‡ - è®­ç»ƒé›†: {len(self.full_train_df)} | éªŒè¯é›†: {len(self.val_df)}  | æµ‹è¯•é›†: {len(self.test_df)}")
        # æ‰“å°æ€§åˆ«åˆ†å¸ƒ
        if 'domain' in self.val_df.columns and 'label' in self.val_df.columns:
            gender_dist = self.val_df[self.val_df['domain'] == 'gender']['label'].value_counts()
            print(f"éªŒè¯é›†æ€§åˆ«åˆ†å¸ƒ: {gender_dist.to_dict()}")

    def sample_train_data(self):
        """åŠ¨æ€é‡‡æ ·ï¼ˆä¼˜åŒ–ï¼šæ€§åˆ«åˆ†ç±»æ ·æœ¬å¹³è¡¡ï¼‰"""
        all_indices = set(self.full_train_df['unique_idx'].tolist())
        remaining_indices = all_indices - self.sampled_indices
        
        if len(remaining_indices) < self.config.MAX_TRAIN_SAMPLES:
            print(f"\nâš ï¸  å‰©ä½™æœªé‡‡æ ·æ•°æ®ä¸è¶³ï¼Œé‡ç½®é‡‡æ ·è®°å½•ï¼ˆå·²è¦†ç›–å…¨é‡æ•°æ®ï¼‰")
            self.sampled_indices = set()
            remaining_indices = all_indices
        
        # ä¼˜åŒ–ï¼šåˆ†å±‚é‡‡æ ·ï¼ˆä¿è¯æ€§åˆ«åˆ†ç±»å„ç±»æ ·æœ¬å‡è¡¡ï¼‰
        def balanced_sample(df, sample_size, remaining_indices):
            df_remaining = df[df['unique_idx'].isin(remaining_indices)]
            
            # å…ˆæŒ‰åŸŸæ‹†åˆ†
            cresci_df = df_remaining[df_remaining['domain'] == 'cresci']
            gender_df = df_remaining[df_remaining['domain'] == 'gender']
            
            # CresciåŸŸï¼šBot/Humanå¹³è¡¡
            cresci_samples = []
            cresci_groups = cresci_df.groupby('label')
            for name, group in cresci_groups:
                sample_num = min(len(group), sample_size//4)  # å æ€»æ ·æœ¬çš„1/2
                cresci_samples.append(group.sample(sample_num, random_state=np.random.randint(1000)))
            cresci_sampled = pd.concat(cresci_samples, ignore_index=True)
            
            # GenderåŸŸï¼šMale/Female/Brandå¹³è¡¡
            gender_samples = []
            gender_groups = gender_df.groupby('label')
            for name, group in gender_groups:
                sample_num = min(len(group), sample_size//6)  # å æ€»æ ·æœ¬çš„1/2ï¼Œ3ç±»å‡åˆ†
                gender_samples.append(group.sample(sample_num, random_state=np.random.randint(1000)))
            gender_sampled = pd.concat(gender_samples, ignore_index=True)
            
            # åˆå¹¶å¹¶è¡¥å……åˆ°æŒ‡å®šå¤§å°
            sampled_df = pd.concat([cresci_sampled, gender_sampled], ignore_index=True)
            if len(sampled_df) < sample_size:
                remaining_df = df_remaining[~df_remaining['unique_idx'].isin(sampled_df['unique_idx'])]
                supplement = remaining_df.sample(sample_size - len(sampled_df), random_state=np.random.randint(1000))
                sampled_df = pd.concat([sampled_df, supplement], ignore_index=True)
            
            return sampled_df.sample(frac=1).head(sample_size)
        
        sampled_train_df = balanced_sample(self.full_train_df, self.config.MAX_TRAIN_SAMPLES, remaining_indices)
        sampled_idx = set(sampled_train_df['unique_idx'].tolist())
        self.sampled_indices.update(sampled_idx)
        
        train_dataset = DualDomainDataset(sampled_train_df, self.tokenizer, self.config.MAX_LENGTH, self.config)
        train_loader = DataLoader(train_dataset, batch_size=self.config.BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=False)
        
        print(f"\nğŸ”„ åŠ¨æ€é‡‡æ ·å®Œæˆ: {len(sampled_train_df)} æ¡")
        print(f"   åŸŸåˆ†å¸ƒ: {sampled_train_df['domain'].value_counts().to_dict()}")
        if 'domain' in sampled_train_df.columns and 'label' in sampled_train_df.columns:
            gender_label_dist = sampled_train_df[sampled_train_df['domain'] == 'gender']['label'].value_counts()
            print(f"   æ€§åˆ«æ ‡ç­¾åˆ†å¸ƒ: {gender_label_dist.to_dict()}")
        print(f"   å·²é‡‡æ ·å æ¯”: {len(self.sampled_indices)}/{len(self.full_train_df)} ({len(self.sampled_indices)/len(self.full_train_df)*100:.1f}%)")
        return train_loader

    def _eval_current_model(self):
        """ä¼˜åŒ–ï¼šè¯¦ç»†è¯„ä¼°ï¼ˆåŸŸå‡†ç¡®ç‡+Bot+æ€§åˆ«åˆ†ç±»å•ç‹¬è¯„ä¼°ï¼‰"""
        if self.val_df is None or len(self.val_df) == 0:
            raise ValueError("ç‹¬ç«‹éªŒè¯é›†æœªåŠ è½½ï¼è¯·å…ˆè°ƒç”¨load_full_data()")
        
        self.model.eval()
        total_correct = 0
        total = 0
        domain_correct = 0
        bot_correct, bot_total = 0, 0
        gender_correct, gender_total = 0, 0
        
        eval_dataset = DualDomainDataset(self.val_df, self.tokenizer, self.config.MAX_LENGTH, self.config)
        eval_loader = DataLoader(eval_dataset, batch_size=self.config.BATCH_SIZE, shuffle=False)
        
        with torch.no_grad():
            for batch in eval_loader:
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                task_labels = batch['task_label'].to(self.device)
                domain_labels = batch['domain_label'].to(self.device)
                domains = batch['domain']
                
                outputs = self.model(input_ids, attention_mask, domains)
                
                # åŸŸåˆ¤åˆ«å‡†ç¡®ç‡
                domain_preds = outputs['domain_logits'].argmax(dim=1)
                domain_correct += (domain_preds == domain_labels).sum().item()
                
                # æ ¸å¿ƒä»»åŠ¡å‡†ç¡®ç‡
                for i, domain in enumerate(domains):
                    pred = outputs['bot_logits'][i].argmax() if domain == 'cresci' else outputs['gender_logits'][i].argmax()
                    total_correct += (pred == task_labels[i]).item()
                    
                    # Bot/æ€§åˆ«åˆ†ç±»å•ç‹¬ç»Ÿè®¡
                    if domain == 'cresci':
                        bot_correct += (pred == task_labels[i]).item()
                        bot_total += 1
                    else:
                        gender_correct += (pred == task_labels[i]).item()
                        gender_total += 1
                total += len(domains)
        
        # è®¡ç®—å„ç±»å‡†ç¡®ç‡
        current_acc = total_correct / total
        domain_acc = domain_correct / total if total > 0 else 0
        bot_acc = bot_correct / bot_total if bot_total > 0 else 0
        gender_acc = gender_correct / gender_total if gender_total > 0 else 0
        
        # è®°å½•å†å²
        self.history['val_acc'].append(current_acc)
        self.history['domain_acc'].append(domain_acc)
        self.history['bot_acc'].append(bot_acc)
        self.history['gender_acc'].append(gender_acc)
        
        print(f"ğŸ“Š è¯„ä¼°è¯¦æƒ… - æ•´ä½“: {current_acc:.4f} | åŸŸåˆ¤åˆ«: {domain_acc:.4f} | Bot: {bot_acc:.4f} | æ€§åˆ«: {gender_acc:.4f}")
        self.model.train()
        return current_acc

    def _save_best_model(self, current_acc, epoch):
        """ä¼˜åŒ–ï¼šä¿å­˜æ›´è¯¦ç»†çš„ä¿¡æ¯"""
        is_best = False
        if current_acc > self.best_val_acc:
            is_best = True
            print(f"\nğŸ“ˆ éªŒè¯é›†å‡†ç¡®ç‡æå‡: {self.best_val_acc:.4f} â†’ {current_acc:.4f}ï¼Œæ ‡è®°ä¸ºæœ€ä¼˜æ¨¡å‹")
            self.best_val_acc = current_acc
            best_model_path = self.original_model_path
        else:
            print(f"\nğŸ“‰ éªŒè¯é›†å‡†ç¡®ç‡æœªæå‡: {current_acc:.4f} â‰¤ {self.best_val_acc:.4f}")

        # ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨ï¼ˆæ–°å¢ï¼šé˜²æ­¢è·¯å¾„ä¸å­˜åœ¨æŠ¥é”™ï¼‰
        os.makedirs(os.path.dirname(self.original_model_path), exist_ok=True)
        
        # ä¿å­˜å½“å‰è½®æ¬¡æ¨¡å‹
        coverage = len(self.sampled_indices) / len(self.full_train_df) * 100
        epoch_model_path = os.path.join(
            os.path.dirname(self.original_model_path),
            f"model_epoch_{epoch+1}_val_{current_acc:.4f}_domain_{self.history['domain_acc'][-1]:.4f}_gender_{self.history['gender_acc'][-1]:.4f}.pt"
        )
        
        # ä¿å­˜å®Œæ•´ä¿¡æ¯
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'epoch': epoch+1,
            'val_acc': current_acc,
            'domain_acc': self.history['domain_acc'][-1],
            'bot_acc': self.history['bot_acc'][-1],
            'gender_acc': self.history['gender_acc'][-1],
            'train_acc': self.history['train_acc'][-1],
            'train_loss': self.history['train_loss'][-1],
            'data_coverage': coverage,
            'sampled_indices': list(self.sampled_indices),
            'config': self.config,
            'is_best': is_best
        }, epoch_model_path)
        print(f"ğŸ’¾ ç¬¬{epoch+1}è½®æ¨¡å‹ä¿å­˜è‡³: {epoch_model_path}")

        # æ›´æ–°æœ€ä¼˜æ¨¡å‹é“¾æ¥
        if is_best:
            if os.name == 'nt':
                # Windowsä¸‹å…ˆåˆ é™¤åŸæœ‰æ–‡ä»¶ï¼ˆé¿å…é“¾æ¥å¤±è´¥ï¼‰
                if os.path.exists(best_model_path):
                    try:
                        os.remove(best_model_path)
                    except:
                        pass
                # å°è¯•åˆ›å»ºç¡¬é“¾æ¥
                try:
                    os.system(f'mklink /H "{best_model_path}" "{epoch_model_path}"')
                except:
                    # é“¾æ¥å¤±è´¥åˆ™ç›´æ¥å¤åˆ¶æ–‡ä»¶
                    import shutil
                    shutil.copyfile(epoch_model_path, best_model_path)
            else:
                if os.path.exists(best_model_path):
                    os.unlink(best_model_path)
                os.symlink(epoch_model_path, best_model_path)
            print(f"ğŸ”– æœ€ä¼˜æ¨¡å‹é“¾æ¥å·²æ›´æ–°ä¸º: {best_model_path}")

    def train(self):
        """æ ¸å¿ƒè®­ç»ƒé€»è¾‘ï¼šä¼˜åŒ–æŸå¤±æƒé‡+åŠ¨æ€alpha+æ ‡ç­¾å¹³æ»‘"""
        print("\n=== æ¨¡å‹è®­ç»ƒï¼ˆæ”¯æŒä»0è®­ç»ƒ/å¢é‡è®­ç»ƒï¼‰===")
        self.load_full_data()
        
        # CPUæ¨¡å¼å†»ç»“å±‚
        if self.device.type == 'cpu' and hasattr(self.config, 'FREEZE_LAYERS') and self.config.FREEZE_LAYERS > 0:
            print(f"âš ï¸  CPUæ¨¡å¼: å†»ç»“DeBERTaå‰{self.config.FREEZE_LAYERS}å±‚")
            for name, param in self.model.deberta.named_parameters():
                if 'embeddings' in name or any(f'layer.{i}.' in name for i in range(self.config.FREEZE_LAYERS)):
                    param.requires_grad = False
        
        # ä¼˜åŒ–å™¨ï¼ˆåŒºåˆ†å¢é‡è®­ç»ƒå’Œä»é›¶è®­ç»ƒçš„å­¦ä¹ ç‡ï¼‰
        if hasattr(self, '_pretrained_loaded') and self._pretrained_loaded:
            # å¢é‡è®­ç»ƒï¼šæ›´ä½çš„å­¦ä¹ ç‡
            lr = self.config.LEARNING_RATE * 0.05
            print(f"â„¹ï¸  å¢é‡è®­ç»ƒæ¨¡å¼ - å­¦ä¹ ç‡: {lr}")
        else:
            # ä»é›¶è®­ç»ƒï¼šæ­£å¸¸å­¦ä¹ ç‡
            lr = self.config.LEARNING_RATE
            print(f"â„¹ï¸  ä»é›¶è®­ç»ƒæ¨¡å¼ - å­¦ä¹ ç‡: {lr}")
        
        optimizer = torch.optim.AdamW(
            filter(lambda p: p.requires_grad, self.model.parameters()),
            lr=lr,
            weight_decay=self.config.WEIGHT_DECAY if hasattr(self.config, 'WEIGHT_DECAY') else 0.005
        )
        
        total_steps = self.config.NUM_EPOCHS * (self.config.MAX_TRAIN_SAMPLES // self.config.BATCH_SIZE)
        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps*0.1), num_training_steps=total_steps)
        
        # ä¼˜åŒ–3ï¼šä½¿ç”¨æ ‡ç­¾å¹³æ»‘æŸå¤±ï¼ˆå‡å°‘è¿‡æ‹Ÿåˆï¼‰
        criterion_domain = LabelSmoothingLoss(self.config.NUM_DOMAINS, smoothing=0.1)
        criterion_task = LabelSmoothingLoss(max(self.config.NUM_BOT_CLASSES, self.config.NUM_GENDER_CLASSES), smoothing=0.1)
        
        # ä¼˜åŒ–4ï¼šè°ƒæ•´æŸå¤±æƒé‡ï¼ˆé™ä½åŸŸæŸå¤±ï¼Œæå‡æ€§åˆ«åˆ†ç±»æƒé‡ï¼‰
        lambda_task = self.config.LAMBDA_TASK if hasattr(self.config, 'LAMBDA_TASK') else 1.0
        lambda_domain = self.config.LAMBDA_DOMAIN if hasattr(self.config, 'LAMBDA_DOMAIN') else 0.3  # é™ä½åŸŸæŸå¤±æƒé‡
        gender_weight = 2.0  # æ€§åˆ«åˆ†ç±»æŸå¤±åŠ æƒ
        
        # å¢é‡è®­ç»ƒ
        for epoch in range(self.config.NUM_EPOCHS):
            print(f"\n{'='*60}")
            print(f"Epoch {epoch+1}/{self.config.NUM_EPOCHS}")
            print(f"{'='*60}")
            
            # ä¼˜åŒ–5ï¼šåŠ¨æ€è°ƒæ•´GRLçš„alphaå€¼ï¼ˆçº¿æ€§å¢åŠ ï¼‰
            alpha = 0.1 + (0.8) * epoch / self.config.NUM_EPOCHS  # ä»0.1å¢åŠ åˆ°0.9
            self.model.grl.set_alpha(alpha)
            print(f"ğŸ”§ å½“å‰GRL alphaå€¼: {alpha:.4f}")
            
            train_loader = self.sample_train_data()
            self.model.train()
            train_loss = 0
            train_correct = 0
            train_total = 0
            start_time = time.time()
            
            pbar = tqdm(train_loader, desc=f"è®­ç»ƒ", disable=(self.device.type == 'cpu'))
            for batch_idx, batch in enumerate(pbar):
                try:
                    # CPUè¿›åº¦æ‰“å°
                    if self.device.type == 'cpu' and batch_idx % self.config.LOG_INTERVAL == 0:
                        elapsed = time.time() - start_time if batch_idx > 0 else 0
                        eta = (elapsed/(batch_idx+1)) * (len(train_loader)-batch_idx-1) if batch_idx > 0 else 0
                        print(f"Batch {batch_idx}/{len(train_loader)} | Loss: {train_loss/(batch_idx+1):.4f} | Acc: {train_correct/max(train_total,1):.4f} | ETA: {eta/60:.1f}min")
                    
                    # å‰å‘/åå‘ä¼ æ’­
                    input_ids = batch['input_ids'].to(self.device)
                    attention_mask = batch['attention_mask'].to(self.device)
                    domain_labels = batch['domain_label'].to(self.device)
                    task_labels = batch['task_label'].to(self.device)
                    domains = batch['domain']
                    
                    outputs = self.model(input_ids, attention_mask, domains)
                    domain_loss = criterion_domain(outputs['domain_logits'], domain_labels)
                    
                    cresci_mask = torch.tensor([d == 'cresci' for d in domains]).to(self.device)
                    gender_mask = ~cresci_mask
                    task_loss = 0
                    
                    # BotæŸå¤±ï¼ˆåŸæœ‰ï¼‰
                    if cresci_mask.any():
                        task_loss += criterion_task(outputs['bot_logits'][cresci_mask], task_labels[cresci_mask])
                    
                    # æ€§åˆ«æŸå¤±ï¼ˆåŠ æƒï¼‰
                    if gender_mask.any():
                        gender_loss = criterion_task(outputs['gender_logits'][gender_mask], task_labels[gender_mask])
                        task_loss += gender_loss * gender_weight  # åŠ æƒæå‡æ€§åˆ«åˆ†ç±»è®­ç»ƒä¼˜å…ˆçº§
                    
                    # æœ€ç»ˆæŸå¤±ï¼ˆé™ä½åŸŸæŸå¤±æƒé‡ï¼‰
                    loss = lambda_task * task_loss + lambda_domain * domain_loss
                    
                    optimizer.zero_grad()
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.MAX_GRAD_NORM if hasattr(self.config, 'MAX_GRAD_NORM') else 1.0)
                    optimizer.step()
                    scheduler.step()
                    
                    # ç»Ÿè®¡
                    train_loss += loss.item()
                    for i, domain in enumerate(domains):
                        pred = outputs['bot_logits'][i].argmax() if domain == 'cresci' else outputs['gender_logits'][i].argmax()
                        train_correct += (pred == task_labels[i]).item()
                    train_total += len(domains)
                    
                    pbar.set_postfix({'loss': f"{loss.item():.4f}", 'acc': f"{train_correct/train_total:.4f}"}) if self.device.type != 'cpu' else None
                    
                    # å†…å­˜æ¸…ç†
                    if batch_idx % 50 == 0:
                        del input_ids, attention_mask, domain_labels, task_labels, outputs, loss, domain_loss, task_loss
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                        gc.collect()
                
                except RuntimeError as e:
                    if "out of memory" in str(e):
                        print(f"\nâš ï¸  GPUå†…å­˜ä¸è¶³! æ¸…ç†åç»§ç»­...")
                        torch.cuda.empty_cache() if torch.cuda.is_available() else None
                        gc.collect()
                        continue
                    else:
                        raise e
            
            # è®°å½•å†å²
            avg_train_loss = train_loss / len(train_loader)
            train_acc = train_correct / train_total
            self.history['train_loss'].append(avg_train_loss)
            self.history['train_acc'].append(train_acc)
            
            print(f"\nEpoch {epoch+1} è®­ç»ƒç»“æœ - Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f}")
            
            # è¯„ä¼°å½“å‰æ¨¡å‹
            current_eval_acc = self._eval_current_model()
            self._save_best_model(current_eval_acc, epoch)
            
            # å†…å­˜æ¸…ç†
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()
        
        # è®­ç»ƒå®Œæˆåæ‰“å°æ±‡æ€»
        print("\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š è®­ç»ƒæ±‡æ€»:")
        print(f"   æœ€ä¼˜éªŒè¯é›†å‡†ç¡®ç‡: {self.best_val_acc:.4f}")
        if len(self.history['domain_acc']) > 0:
            print(f"   æœ€ç»ˆåŸŸåˆ¤åˆ«å‡†ç¡®ç‡: {self.history['domain_acc'][-1]:.4f}")
            print(f"   æœ€ç»ˆBotæ£€æµ‹å‡†ç¡®ç‡: {self.history['bot_acc'][-1]:.4f}")
            print(f"   æœ€ç»ˆæ€§åˆ«åˆ†ç±»å‡†ç¡®ç‡: {self.history['gender_acc'][-1]:.4f}")
        print(f"âœ“ æœ€ä¼˜æ¨¡å‹è·¯å¾„: {self.original_model_path}")

# ==================== ä¸»å‡½æ•° ====================
def main():
    from config import Config
    
    print("=" * 60)
    print("æ¨¡å‹è®­ç»ƒä¸»ç¨‹åº (æ”¯æŒä»0è®­ç»ƒ/å¢é‡è®­ç»ƒ)")
    print("=" * 60)
    
    config = Config()
    trainer = DomainAdaptationTrainer(config)
    trainer.train()
    
    print("\n" + "=" * 60)
    print("âœ… è®­ç»ƒæµç¨‹å®Œæˆ!")
    print("=" * 60)

if __name__ == "__main__":
    main()